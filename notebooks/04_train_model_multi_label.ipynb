{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenifer/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPModel, CLIPTokenizer\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenifer/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(text_list):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, sublinear_tf=True)\n",
    "    vectors = vectorizer.fit_transform(text_list)\n",
    "    return vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentence_embeddings(text_list, batch_size=256):\n",
    "    embeddings = []\n",
    "    text_list = [text.strip() for text in text_list]\n",
    "\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        batch_embeddings = model_bert.encode(batch)\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    # Concatenate all batch embeddings\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clip_embeddings(text_list, batch_size=256):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model_clip.get_text_features(**inputs).cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_with_undersampling(X, y, embedding_name, source_text):\n",
    "    # Stratified K-Fold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Random undersampling for balancing classes\n",
    "    #rus = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
    "\n",
    "    # Create the RandomForest model\n",
    "    base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # One-vs-Rest Classifier with custom pipeline that applies undersampling\n",
    "    clf = OneVsRestClassifier(\n",
    "        make_pipeline(RandomUnderSampler(sampling_strategy='not minority', random_state=42), base_rf),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f'Fold Results for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n",
    "        print('-----------------------------------')\n",
    "\n",
    "    # Average metrics over all folds\n",
    "    print(f'Final Cross-Validated Results for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "    print(f'Average Accuracy: {sum(accuracy_scores)/len(accuracy_scores):.4f}')\n",
    "    print(f'Average Precision: {sum(precision_scores)/len(precision_scores):.4f}')\n",
    "    print(f'Average Recall: {sum(recall_scores)/len(recall_scores):.4f}')\n",
    "    print(f'Average F1-Score: {sum(f1_scores)/len(f1_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_ORDER = [\"Computer Vision\", \"Graphs\", \"Natural Language Processing\",\n",
    "               \"Reinforcement Learning\", \"Sequential\", \"Audio\"]\n",
    "\n",
    "def _ensure_multilabel_indicator(y, classes=None):\n",
    "    \"\"\"Return a proper (n_samples, n_classes) 0/1 array from:\n",
    "       - pandas Series of lists/sets/tuples\n",
    "       - list of lists/sets/tuples\n",
    "       - already-binarized 2D numpy/sparse matrix.\"\"\"\n",
    "    classes = classes or CLASS_ORDER\n",
    "\n",
    "    # Already a 2D numpy array of 0/1?\n",
    "    if isinstance(y, np.ndarray) and y.ndim == 2:\n",
    "        uniq = np.unique(y)\n",
    "        if set(uniq).issubset({0, 1}):\n",
    "            return y\n",
    "        raise ValueError(\"2D y provided but contains values other than {0,1}.\")\n",
    "\n",
    "    # Try scipy sparse directly\n",
    "    try:\n",
    "        from scipy import sparse\n",
    "        if sparse.issparse(y):\n",
    "            return y\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Pandas Series of lists/sets/tuples\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        if isinstance(y, pd.Series):\n",
    "            y_list = y.tolist()\n",
    "        else:\n",
    "            y_list = y\n",
    "    except Exception:\n",
    "        y_list = y\n",
    "\n",
    "    # List-like multilabel sequences?\n",
    "    if isinstance(y_list, (list, tuple)) and len(y_list) > 0 and isinstance(y_list[0], (list, tuple, set)):\n",
    "        mlb = MultiLabelBinarizer(classes=classes)\n",
    "        return mlb.fit_transform(y_list)\n",
    "\n",
    "    raise ValueError(\n",
    "        \"y must be a (n_samples, n_classes) 0/1 array/sparse matrix or a Series/list of label-iterables.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_multilabel(X, y, embedding_name, source_text, classes=CLASS_ORDER, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train a Random Forest in a multi-label One-vs-Rest scheme with undersampling.\n",
    "    Handles Series-of-lists or already binarized multilabel indicator matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- ensure y is a proper multilabel-indicator ---\n",
    "    if not (isinstance(y, np.ndarray) and y.ndim == 2 and set(np.unique(y)) <= {0, 1}):\n",
    "        # assume y is list/Series of lists -> convert\n",
    "        mlb = MultiLabelBinarizer(classes=classes)\n",
    "        y = mlb.fit_transform(y)\n",
    "        print(\"Converted labels with MultiLabelBinarizer. Shape:\", y.shape)\n",
    "\n",
    "    # Multilabel Stratified K-Fold for cross-validation\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # RandomForest base model\n",
    "    base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # One-vs-Rest Classifier with undersampling inside imblearn Pipeline\n",
    "    clf = OneVsRestClassifier(\n",
    "        ImbPipeline(steps=[\n",
    "            ('undersample', RandomUnderSampler(sampling_strategy=\"not minority\", random_state=42)),\n",
    "            ('rf', base_rf)\n",
    "        ]),\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Store metrics\n",
    "    subset_acc_scores, hamming_scores = [], []\n",
    "    precision_micro_scores, recall_micro_scores = [], []\n",
    "    f1_micro_scores, f1_macro_scores = [], []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_index, test_index in mskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Multi-label metrics\n",
    "        subset_acc = accuracy_score(y_test, y_pred)  # exact match ratio\n",
    "        hamming = hamming_loss(y_test, y_pred)\n",
    "        precision_micro = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "        recall_micro = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "        f1_micro = f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        subset_acc_scores.append(subset_acc)\n",
    "        hamming_scores.append(hamming)\n",
    "        precision_micro_scores.append(precision_micro)\n",
    "        recall_micro_scores.append(recall_micro)\n",
    "        f1_micro_scores.append(f1_micro)\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "\n",
    "        print(f'Fold Results for {embedding_name} (OvR RF, Multi-label) - {source_text}:')\n",
    "        print(classification_report(y_test, y_pred, zero_division=0, target_names=classes))\n",
    "        print(f'Subset Accuracy: {subset_acc:.4f}, Hamming Loss: {hamming:.4f}, '\n",
    "              f'Precision (micro): {precision_micro:.4f}, Recall (micro): {recall_micro:.4f}, '\n",
    "              f'F1 (micro): {f1_micro:.4f}, F1 (macro): {f1_macro:.4f}')\n",
    "        print('-----------------------------------')\n",
    "\n",
    "    # Average metrics\n",
    "    print(f'Final Cross-Validated Results for {embedding_name} (OvR RF, Multi-label) - {source_text}:')\n",
    "    print(f'Average Subset Accuracy: {np.mean(subset_acc_scores):.4f}')\n",
    "    print(f'Average Hamming Loss: {np.mean(hamming_scores):.4f}')\n",
    "    print(f'Average Precision (micro): {np.mean(precision_micro_scores):.4f}')\n",
    "    print(f'Average Recall (micro): {np.mean(recall_micro_scores):.4f}')\n",
    "    print(f'Average F1 (micro): {np.mean(f1_micro_scores):.4f}')\n",
    "    print(f'Average F1 (macro): {np.mean(f1_macro_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering_metrics(X, y, embedding_name, source_text):\n",
    "    print(f'Clustering metrics for {embedding_name} - {source_text}:')\n",
    "    # Calculate metrics\n",
    "    silhouette_avg = silhouette_score(X, y)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, y)\n",
    "    davies_bouldin = davies_bouldin_score(X, y)\n",
    "    \n",
    "    # Return results in a dictionary\n",
    "    metrics = {\n",
    "        'Silhouette Score': silhouette_avg,\n",
    "        'Calinski-Harabasz Index': calinski_harabasz,\n",
    "        'Davies-Bouldin Index': davies_bouldin\n",
    "    }\n",
    "    \n",
    "    table = [[\"Metric\", \"Score\"]]\n",
    "    for metric, score in metrics.items():\n",
    "        table.append([metric, f\"{score:.4f}\"])\n",
    "    \n",
    "    print(f'Clustering metrics for {embedding_name} (OvR Random Forest) - {source_text}:')\n",
    "    print(f'Silhouette Score: {silhouette_avg:.4f}')\n",
    "    print(f'Calinski-Harabasz Index: {calinski_harabasz:.4f}')\n",
    "    print(f'Davies-Bouldin Index: {davies_bouldin:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n",
      "Number of samples: 9954\n"
     ]
    }
   ],
   "source": [
    "print('Load data')\n",
    "with open('../data/to_be_published/paper_title_abstract_dataset_multi_label.json', 'r') as f:\n",
    "    papers_data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(papers_data)\n",
    "print(f'Number of samples: {df.shape[0]}')\n",
    "\n",
    "titles = df['paper_title'].tolist()\n",
    "abstracts = df['abstract'].tolist()\n",
    "readmes = df['github_readme_content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmes = df['preprocessed_readme_content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for somef decriptions\n",
      "Number of samples: 4050\n"
     ]
    }
   ],
   "source": [
    "print('Load data for somef decriptions')\n",
    "with open('../data/to_be_published/paper_title_abstract_software_readme_description_dataset_multi_label.json', 'r') as f:\n",
    "    papers_data_somef = json.load(f)\n",
    "\n",
    "df_somef = pd.DataFrame(papers_data_somef)\n",
    "print(f'Number of samples: {df_somef.shape[0]}')\n",
    "\n",
    "somef = df_somef['somef_descriptions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data for github titles and keywords\n",
      "Number of samples: 1289\n"
     ]
    }
   ],
   "source": [
    "print('Load data for github titles and keywords')\n",
    "with open('../data/to_be_published/paper_title_abstract_software_readme_description_title_keyword_dataset_multi_label.json', 'r') as f:\n",
    "    papers_data_complete = json.load(f)\n",
    "\n",
    "df_complete = pd.DataFrame(papers_data_complete)\n",
    "print(f'Number of samples: {df_complete.shape[0]}')\n",
    "github_title = df_complete['github_repo_title'].tolist()\n",
    "github_keywords = df_complete['github_keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['main_collection_area']\n",
    "y_somef = df_somef['main_collection_area']\n",
    "y_complete = df_complete['main_collection_area']\n",
    "# num_clusters = len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.76      0.83      1657\n",
      "                     Graphs       0.60      0.66      0.63       501\n",
      "Natural Language Processing       0.85      0.76      0.80      1292\n",
      "     Reinforcement Learning       0.48      0.83      0.61       268\n",
      "                 Sequential       0.48      0.74      0.59       412\n",
      "                      Audio       0.34      0.85      0.48        66\n",
      "\n",
      "                  micro avg       0.72      0.75      0.74      4196\n",
      "                  macro avg       0.61      0.77      0.66      4196\n",
      "               weighted avg       0.78      0.75      0.75      4196\n",
      "                samples avg       0.75      0.75      0.74      4196\n",
      "\n",
      "Subset Accuracy: 0.4047, Hamming Loss: 0.1829, Precision (micro): 0.7246, Recall (micro): 0.7519, F1 (micro): 0.7380, F1 (macro): 0.6555\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.67      0.77      1499\n",
      "                     Graphs       0.65      0.72      0.68       501\n",
      "Natural Language Processing       0.87      0.75      0.81      1293\n",
      "     Reinforcement Learning       0.50      0.76      0.60       268\n",
      "                 Sequential       0.43      0.77      0.55       413\n",
      "                      Audio       0.30      0.71      0.42        65\n",
      "\n",
      "                  micro avg       0.71      0.72      0.72      4039\n",
      "                  macro avg       0.61      0.73      0.64      4039\n",
      "               weighted avg       0.78      0.72      0.73      4039\n",
      "                samples avg       0.74      0.72      0.71      4039\n",
      "\n",
      "Subset Accuracy: 0.3708, Hamming Loss: 0.1971, Precision (micro): 0.7113, Recall (micro): 0.7197, F1 (micro): 0.7155, F1 (macro): 0.6385\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.70      0.79      1530\n",
      "                     Graphs       0.60      0.71      0.65       502\n",
      "Natural Language Processing       0.85      0.73      0.79      1293\n",
      "     Reinforcement Learning       0.48      0.76      0.59       268\n",
      "                 Sequential       0.46      0.79      0.58       413\n",
      "                      Audio       0.32      0.76      0.45        66\n",
      "\n",
      "                  micro avg       0.71      0.73      0.72      4072\n",
      "                  macro avg       0.60      0.74      0.64      4072\n",
      "               weighted avg       0.77      0.73      0.73      4072\n",
      "                samples avg       0.74      0.73      0.71      4072\n",
      "\n",
      "Subset Accuracy: 0.3764, Hamming Loss: 0.1973, Precision (micro): 0.7059, Recall (micro): 0.7267, F1 (micro): 0.7161, F1 (macro): 0.6415\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.72      0.80      1582\n",
      "                     Graphs       0.61      0.73      0.66       502\n",
      "Natural Language Processing       0.87      0.78      0.82      1292\n",
      "     Reinforcement Learning       0.55      0.74      0.63       267\n",
      "                 Sequential       0.45      0.76      0.57       413\n",
      "                      Audio       0.32      0.86      0.47        66\n",
      "\n",
      "                  micro avg       0.73      0.75      0.74      4122\n",
      "                  macro avg       0.62      0.77      0.66      4122\n",
      "               weighted avg       0.79      0.75      0.75      4122\n",
      "                samples avg       0.76      0.75      0.73      4122\n",
      "\n",
      "Subset Accuracy: 0.3705, Hamming Loss: 0.1837, Precision (micro): 0.7289, Recall (micro): 0.7455, F1 (micro): 0.7371, F1 (macro): 0.6607\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.67      0.77      1566\n",
      "                     Graphs       0.60      0.67      0.63       502\n",
      "Natural Language Processing       0.85      0.76      0.80      1293\n",
      "     Reinforcement Learning       0.46      0.84      0.59       267\n",
      "                 Sequential       0.43      0.79      0.56       413\n",
      "                      Audio       0.32      0.80      0.46        66\n",
      "\n",
      "                  micro avg       0.70      0.72      0.71      4107\n",
      "                  macro avg       0.60      0.75      0.64      4107\n",
      "               weighted avg       0.77      0.72      0.73      4107\n",
      "                samples avg       0.73      0.72      0.71      4107\n",
      "\n",
      "Subset Accuracy: 0.3422, Hamming Loss: 0.2048, Precision (micro): 0.6958, Recall (micro): 0.7202, F1 (micro): 0.7078, F1 (macro): 0.6353\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - Title:\n",
      "Average Subset Accuracy: 0.3729\n",
      "Average Hamming Loss: 0.1932\n",
      "Average Precision (micro): 0.7133\n",
      "Average Recall (micro): 0.7328\n",
      "Average F1 (micro): 0.7229\n",
      "Average F1 (macro): 0.6463\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(titles)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y, 'TF-IDF', 'Title')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.75      0.83      1657\n",
      "                     Graphs       0.58      0.59      0.58       501\n",
      "Natural Language Processing       0.82      0.77      0.79      1292\n",
      "     Reinforcement Learning       0.64      0.81      0.71       268\n",
      "                 Sequential       0.45      0.74      0.56       412\n",
      "                      Audio       0.36      0.83      0.50        66\n",
      "\n",
      "                  micro avg       0.73      0.74      0.74      4196\n",
      "                  macro avg       0.63      0.75      0.66      4196\n",
      "               weighted avg       0.78      0.74      0.75      4196\n",
      "                samples avg       0.76      0.74      0.73      4196\n",
      "\n",
      "Subset Accuracy: 0.3998, Hamming Loss: 0.1811, Precision (micro): 0.7339, Recall (micro): 0.7395, F1 (micro): 0.7367, F1 (macro): 0.6627\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.74      0.81      1499\n",
      "                     Graphs       0.63      0.67      0.65       501\n",
      "Natural Language Processing       0.85      0.76      0.80      1293\n",
      "     Reinforcement Learning       0.63      0.74      0.68       268\n",
      "                 Sequential       0.44      0.74      0.55       413\n",
      "                      Audio       0.34      0.77      0.47        65\n",
      "\n",
      "                  micro avg       0.73      0.74      0.73      4039\n",
      "                  macro avg       0.63      0.74      0.66      4039\n",
      "               weighted avg       0.78      0.74      0.75      4039\n",
      "                samples avg       0.75      0.74      0.73      4039\n",
      "\n",
      "Subset Accuracy: 0.3903, Hamming Loss: 0.1855, Precision (micro): 0.7283, Recall (micro): 0.7358, F1 (micro): 0.7320, F1 (macro): 0.6597\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.75      0.82      1530\n",
      "                     Graphs       0.59      0.69      0.64       502\n",
      "Natural Language Processing       0.84      0.74      0.79      1293\n",
      "     Reinforcement Learning       0.64      0.74      0.68       268\n",
      "                 Sequential       0.49      0.78      0.60       413\n",
      "                      Audio       0.38      0.79      0.51        66\n",
      "\n",
      "                  micro avg       0.74      0.74      0.74      4072\n",
      "                  macro avg       0.64      0.75      0.67      4072\n",
      "               weighted avg       0.78      0.74      0.75      4072\n",
      "                samples avg       0.76      0.75      0.74      4072\n",
      "\n",
      "Subset Accuracy: 0.3966, Hamming Loss: 0.1785, Precision (micro): 0.7370, Recall (micro): 0.7441, F1 (micro): 0.7406, F1 (macro): 0.6732\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.73      0.81      1582\n",
      "                     Graphs       0.59      0.69      0.64       502\n",
      "Natural Language Processing       0.86      0.76      0.81      1292\n",
      "     Reinforcement Learning       0.60      0.79      0.68       267\n",
      "                 Sequential       0.45      0.72      0.55       413\n",
      "                      Audio       0.37      0.85      0.51        66\n",
      "\n",
      "                  micro avg       0.73      0.74      0.74      4122\n",
      "                  macro avg       0.63      0.76      0.67      4122\n",
      "               weighted avg       0.78      0.74      0.75      4122\n",
      "                samples avg       0.76      0.75      0.73      4122\n",
      "\n",
      "Subset Accuracy: 0.3937, Hamming Loss: 0.1828, Precision (micro): 0.7330, Recall (micro): 0.7407, F1 (micro): 0.7368, F1 (macro): 0.6675\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.73      0.81      1566\n",
      "                     Graphs       0.60      0.62      0.61       502\n",
      "Natural Language Processing       0.84      0.74      0.79      1293\n",
      "     Reinforcement Learning       0.59      0.80      0.68       267\n",
      "                 Sequential       0.45      0.73      0.56       413\n",
      "                      Audio       0.40      0.89      0.55        66\n",
      "\n",
      "                  micro avg       0.73      0.73      0.73      4107\n",
      "                  macro avg       0.63      0.75      0.67      4107\n",
      "               weighted avg       0.78      0.73      0.74      4107\n",
      "                samples avg       0.75      0.73      0.72      4107\n",
      "\n",
      "Subset Accuracy: 0.3764, Hamming Loss: 0.1863, Precision (micro): 0.7307, Recall (micro): 0.7273, F1 (micro): 0.7290, F1 (macro): 0.6662\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - Title:\n",
      "Average Subset Accuracy: 0.3914\n",
      "Average Hamming Loss: 0.1828\n",
      "Average Precision (micro): 0.7326\n",
      "Average Recall (micro): 0.7375\n",
      "Average F1 (micro): 0.7350\n",
      "Average F1 (macro): 0.6659\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(titles)\n",
    "train_random_forest_multilabel(sentence_embeddings, y, 'Sentence Transformer', 'Title')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.71      0.80      1657\n",
      "                     Graphs       0.51      0.59      0.55       501\n",
      "Natural Language Processing       0.80      0.74      0.77      1292\n",
      "     Reinforcement Learning       0.48      0.76      0.59       268\n",
      "                 Sequential       0.40      0.69      0.51       412\n",
      "                      Audio       0.26      0.80      0.40        66\n",
      "\n",
      "                  micro avg       0.68      0.71      0.69      4196\n",
      "                  macro avg       0.56      0.72      0.60      4196\n",
      "               weighted avg       0.74      0.71      0.71      4196\n",
      "                samples avg       0.71      0.71      0.69      4196\n",
      "\n",
      "Subset Accuracy: 0.3332, Hamming Loss: 0.2156, Precision (micro): 0.6769, Recall (micro): 0.7095, F1 (micro): 0.6928, F1 (macro): 0.6027\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.69      0.78      1499\n",
      "                     Graphs       0.54      0.65      0.59       501\n",
      "Natural Language Processing       0.84      0.74      0.79      1293\n",
      "     Reinforcement Learning       0.53      0.69      0.60       268\n",
      "                 Sequential       0.39      0.68      0.50       413\n",
      "                      Audio       0.27      0.71      0.39        65\n",
      "\n",
      "                  micro avg       0.69      0.70      0.69      4039\n",
      "                  macro avg       0.58      0.69      0.61      4039\n",
      "               weighted avg       0.75      0.70      0.71      4039\n",
      "                samples avg       0.72      0.71      0.69      4039\n",
      "\n",
      "Subset Accuracy: 0.3279, Hamming Loss: 0.2129, Precision (micro): 0.6866, Recall (micro): 0.7024, F1 (micro): 0.6944, F1 (macro): 0.6094\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.89      0.71      0.79      1530\n",
      "                     Graphs       0.52      0.68      0.59       502\n",
      "Natural Language Processing       0.82      0.70      0.76      1293\n",
      "     Reinforcement Learning       0.49      0.68      0.57       268\n",
      "                 Sequential       0.40      0.70      0.51       413\n",
      "                      Audio       0.27      0.79      0.40        66\n",
      "\n",
      "                  micro avg       0.67      0.70      0.69      4072\n",
      "                  macro avg       0.57      0.71      0.60      4072\n",
      "               weighted avg       0.74      0.70      0.71      4072\n",
      "                samples avg       0.70      0.71      0.68      4072\n",
      "\n",
      "Subset Accuracy: 0.3290, Hamming Loss: 0.2197, Precision (micro): 0.6712, Recall (micro): 0.7024, F1 (micro): 0.6864, F1 (macro): 0.6036\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.69      0.79      1582\n",
      "                     Graphs       0.50      0.67      0.58       502\n",
      "Natural Language Processing       0.85      0.73      0.78      1292\n",
      "     Reinforcement Learning       0.51      0.74      0.60       267\n",
      "                 Sequential       0.39      0.67      0.50       413\n",
      "                      Audio       0.28      0.79      0.41        66\n",
      "\n",
      "                  micro avg       0.68      0.70      0.69      4122\n",
      "                  macro avg       0.58      0.71      0.61      4122\n",
      "               weighted avg       0.76      0.70      0.71      4122\n",
      "                samples avg       0.71      0.71      0.69      4122\n",
      "\n",
      "Subset Accuracy: 0.3122, Hamming Loss: 0.2159, Precision (micro): 0.6821, Recall (micro): 0.7026, F1 (micro): 0.6922, F1 (macro): 0.6097\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.66      0.76      1566\n",
      "                     Graphs       0.49      0.58      0.53       502\n",
      "Natural Language Processing       0.83      0.74      0.79      1293\n",
      "     Reinforcement Learning       0.46      0.76      0.58       267\n",
      "                 Sequential       0.40      0.66      0.50       413\n",
      "                      Audio       0.29      0.79      0.43        66\n",
      "\n",
      "                  micro avg       0.67      0.69      0.68      4107\n",
      "                  macro avg       0.56      0.70      0.60      4107\n",
      "               weighted avg       0.74      0.69      0.70      4107\n",
      "                samples avg       0.69      0.69      0.67      4107\n",
      "\n",
      "Subset Accuracy: 0.3080, Hamming Loss: 0.2245, Precision (micro): 0.6702, Recall (micro): 0.6857, F1 (micro): 0.6778, F1 (macro): 0.5964\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - Title:\n",
      "Average Subset Accuracy: 0.3220\n",
      "Average Hamming Loss: 0.2177\n",
      "Average Precision (micro): 0.6774\n",
      "Average Recall (micro): 0.7005\n",
      "Average F1 (micro): 0.6887\n",
      "Average F1 (macro): 0.6044\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(titles)\n",
    "train_random_forest_multilabel(clip_embeddings, y, 'CLIP', 'Title')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.96      0.85      0.90      1657\n",
      "                     Graphs       0.78      0.86      0.82       501\n",
      "Natural Language Processing       0.92      0.93      0.92      1292\n",
      "     Reinforcement Learning       0.78      0.88      0.83       268\n",
      "                 Sequential       0.72      0.90      0.80       412\n",
      "                      Audio       0.46      0.86      0.60        66\n",
      "\n",
      "                  micro avg       0.87      0.88      0.87      4196\n",
      "                  macro avg       0.77      0.88      0.81      4196\n",
      "               weighted avg       0.88      0.88      0.88      4196\n",
      "                samples avg       0.88      0.88      0.87      4196\n",
      "\n",
      "Subset Accuracy: 0.6301, Hamming Loss: 0.0879, Precision (micro): 0.8655, Recall (micro): 0.8804, F1 (micro): 0.8729, F1 (macro): 0.8110\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.94      0.86      0.90      1499\n",
      "                     Graphs       0.78      0.91      0.84       501\n",
      "Natural Language Processing       0.94      0.92      0.93      1293\n",
      "     Reinforcement Learning       0.76      0.84      0.80       268\n",
      "                 Sequential       0.68      0.86      0.76       413\n",
      "                      Audio       0.41      0.85      0.55        65\n",
      "\n",
      "                  micro avg       0.86      0.88      0.87      4039\n",
      "                  macro avg       0.75      0.87      0.80      4039\n",
      "               weighted avg       0.87      0.88      0.88      4039\n",
      "                samples avg       0.88      0.89      0.87      4039\n",
      "\n",
      "Subset Accuracy: 0.6138, Hamming Loss: 0.0909, Precision (micro): 0.8560, Recall (micro): 0.8849, F1 (micro): 0.8702, F1 (macro): 0.7964\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.94      0.88      0.91      1530\n",
      "                     Graphs       0.78      0.89      0.84       502\n",
      "Natural Language Processing       0.94      0.92      0.93      1293\n",
      "     Reinforcement Learning       0.77      0.84      0.80       268\n",
      "                 Sequential       0.70      0.86      0.77       413\n",
      "                      Audio       0.42      0.89      0.58        66\n",
      "\n",
      "                  micro avg       0.86      0.89      0.88      4072\n",
      "                  macro avg       0.76      0.88      0.80      4072\n",
      "               weighted avg       0.88      0.89      0.88      4072\n",
      "                samples avg       0.88      0.89      0.87      4072\n",
      "\n",
      "Subset Accuracy: 0.6276, Hamming Loss: 0.0869, Precision (micro): 0.8622, Recall (micro): 0.8883, F1 (micro): 0.8750, F1 (macro): 0.8044\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.96      0.85      0.90      1582\n",
      "                     Graphs       0.78      0.90      0.84       502\n",
      "Natural Language Processing       0.94      0.93      0.93      1292\n",
      "     Reinforcement Learning       0.74      0.87      0.80       267\n",
      "                 Sequential       0.71      0.88      0.78       413\n",
      "                      Audio       0.42      0.91      0.57        66\n",
      "\n",
      "                  micro avg       0.86      0.88      0.87      4122\n",
      "                  macro avg       0.76      0.89      0.80      4122\n",
      "               weighted avg       0.88      0.88      0.88      4122\n",
      "                samples avg       0.88      0.89      0.87      4122\n",
      "\n",
      "Subset Accuracy: 0.6234, Hamming Loss: 0.0885, Precision (micro): 0.8629, Recall (micro): 0.8843, F1 (micro): 0.8735, F1 (macro): 0.8031\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.95      0.83      0.88      1566\n",
      "                     Graphs       0.76      0.89      0.82       502\n",
      "Natural Language Processing       0.93      0.91      0.92      1293\n",
      "     Reinforcement Learning       0.75      0.85      0.79       267\n",
      "                 Sequential       0.69      0.85      0.76       413\n",
      "                      Audio       0.45      0.94      0.61        66\n",
      "\n",
      "                  micro avg       0.86      0.87      0.86      4107\n",
      "                  macro avg       0.76      0.88      0.80      4107\n",
      "               weighted avg       0.88      0.87      0.87      4107\n",
      "                samples avg       0.88      0.87      0.86      4107\n",
      "\n",
      "Subset Accuracy: 0.5949, Hamming Loss: 0.0960, Precision (micro): 0.8570, Recall (micro): 0.8656, F1 (micro): 0.8613, F1 (macro): 0.7994\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - Abstract:\n",
      "Average Subset Accuracy: 0.6180\n",
      "Average Hamming Loss: 0.0900\n",
      "Average Precision (micro): 0.8607\n",
      "Average Recall (micro): 0.8807\n",
      "Average F1 (micro): 0.8706\n",
      "Average F1 (macro): 0.8028\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(abstracts)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y, 'TF-IDF', 'Abstract')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.77      0.84      1657\n",
      "                     Graphs       0.71      0.70      0.70       501\n",
      "Natural Language Processing       0.85      0.80      0.83      1292\n",
      "     Reinforcement Learning       0.69      0.85      0.76       268\n",
      "                 Sequential       0.55      0.81      0.65       412\n",
      "                      Audio       0.44      0.83      0.58        66\n",
      "\n",
      "                  micro avg       0.79      0.78      0.79      4196\n",
      "                  macro avg       0.69      0.80      0.73      4196\n",
      "               weighted avg       0.82      0.78      0.79      4196\n",
      "                samples avg       0.81      0.79      0.78      4196\n",
      "\n",
      "Subset Accuracy: 0.4855, Hamming Loss: 0.1457, Precision (micro): 0.7896, Recall (micro): 0.7836, F1 (micro): 0.7866, F1 (macro): 0.7275\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.78      0.84      1499\n",
      "                     Graphs       0.67      0.75      0.71       501\n",
      "Natural Language Processing       0.88      0.80      0.84      1293\n",
      "     Reinforcement Learning       0.70      0.78      0.74       268\n",
      "                 Sequential       0.55      0.80      0.65       413\n",
      "                      Audio       0.40      0.82      0.53        65\n",
      "\n",
      "                  micro avg       0.78      0.78      0.78      4039\n",
      "                  macro avg       0.69      0.79      0.72      4039\n",
      "               weighted avg       0.81      0.78      0.79      4039\n",
      "                samples avg       0.81      0.79      0.78      4039\n",
      "\n",
      "Subset Accuracy: 0.4650, Hamming Loss: 0.1488, Precision (micro): 0.7836, Recall (micro): 0.7844, F1 (micro): 0.7840, F1 (macro): 0.7183\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.80      0.85      1530\n",
      "                     Graphs       0.67      0.77      0.72       502\n",
      "Natural Language Processing       0.89      0.80      0.84      1293\n",
      "     Reinforcement Learning       0.72      0.77      0.74       268\n",
      "                 Sequential       0.58      0.81      0.68       413\n",
      "                      Audio       0.48      0.83      0.61        66\n",
      "\n",
      "                  micro avg       0.80      0.80      0.80      4072\n",
      "                  macro avg       0.71      0.80      0.74      4072\n",
      "               weighted avg       0.82      0.80      0.80      4072\n",
      "                samples avg       0.82      0.80      0.79      4072\n",
      "\n",
      "Subset Accuracy: 0.4844, Hamming Loss: 0.1392, Precision (micro): 0.7977, Recall (micro): 0.7952, F1 (micro): 0.7965, F1 (macro): 0.7400\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.77      0.84      1582\n",
      "                     Graphs       0.69      0.78      0.74       502\n",
      "Natural Language Processing       0.89      0.80      0.84      1292\n",
      "     Reinforcement Learning       0.69      0.82      0.75       267\n",
      "                 Sequential       0.54      0.77      0.64       413\n",
      "                      Audio       0.46      0.89      0.61        66\n",
      "\n",
      "                  micro avg       0.79      0.79      0.79      4122\n",
      "                  macro avg       0.70      0.81      0.73      4122\n",
      "               weighted avg       0.82      0.79      0.80      4122\n",
      "                samples avg       0.82      0.79      0.79      4122\n",
      "\n",
      "Subset Accuracy: 0.4786, Hamming Loss: 0.1442, Precision (micro): 0.7940, Recall (micro): 0.7865, F1 (micro): 0.7902, F1 (macro): 0.7343\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.78      0.84      1566\n",
      "                     Graphs       0.71      0.74      0.72       502\n",
      "Natural Language Processing       0.88      0.80      0.84      1293\n",
      "     Reinforcement Learning       0.70      0.85      0.77       267\n",
      "                 Sequential       0.56      0.79      0.66       413\n",
      "                      Audio       0.47      0.86      0.61        66\n",
      "\n",
      "                  micro avg       0.80      0.79      0.79      4107\n",
      "                  macro avg       0.71      0.80      0.74      4107\n",
      "               weighted avg       0.83      0.79      0.80      4107\n",
      "                samples avg       0.82      0.79      0.79      4107\n",
      "\n",
      "Subset Accuracy: 0.4852, Hamming Loss: 0.1412, Precision (micro): 0.7994, Recall (micro): 0.7879, F1 (micro): 0.7936, F1 (macro): 0.7407\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - Abstract:\n",
      "Average Subset Accuracy: 0.4797\n",
      "Average Hamming Loss: 0.1438\n",
      "Average Precision (micro): 0.7929\n",
      "Average Recall (micro): 0.7875\n",
      "Average F1 (micro): 0.7902\n",
      "Average F1 (macro): 0.7322\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(abstracts)\n",
    "train_random_forest_multilabel(sentence_embeddings, y, 'Sentence Transformer', 'Abstract')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.70      0.80      1657\n",
      "                     Graphs       0.44      0.59      0.50       501\n",
      "Natural Language Processing       0.80      0.75      0.77      1292\n",
      "     Reinforcement Learning       0.49      0.77      0.60       268\n",
      "                 Sequential       0.41      0.70      0.52       412\n",
      "                      Audio       0.26      0.80      0.40        66\n",
      "\n",
      "                  micro avg       0.67      0.71      0.69      4196\n",
      "                  macro avg       0.55      0.72      0.60      4196\n",
      "               weighted avg       0.74      0.71      0.71      4196\n",
      "                samples avg       0.69      0.71      0.68      4196\n",
      "\n",
      "Subset Accuracy: 0.2989, Hamming Loss: 0.2214, Precision (micro): 0.6664, Recall (micro): 0.7085, F1 (micro): 0.6868, F1 (macro): 0.5985\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.68      0.78      1499\n",
      "                     Graphs       0.46      0.57      0.51       501\n",
      "Natural Language Processing       0.82      0.71      0.77      1293\n",
      "     Reinforcement Learning       0.46      0.73      0.56       268\n",
      "                 Sequential       0.39      0.71      0.51       413\n",
      "                      Audio       0.24      0.77      0.37        65\n",
      "\n",
      "                  micro avg       0.65      0.69      0.67      4039\n",
      "                  macro avg       0.55      0.70      0.58      4039\n",
      "               weighted avg       0.73      0.69      0.69      4039\n",
      "                samples avg       0.68      0.69      0.67      4039\n",
      "\n",
      "Subset Accuracy: 0.2864, Hamming Loss: 0.2341, Precision (micro): 0.6524, Recall (micro): 0.6851, F1 (micro): 0.6684, F1 (macro): 0.5817\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.72      0.80      1530\n",
      "                     Graphs       0.45      0.58      0.51       502\n",
      "Natural Language Processing       0.82      0.73      0.78      1293\n",
      "     Reinforcement Learning       0.48      0.74      0.58       268\n",
      "                 Sequential       0.45      0.72      0.56       413\n",
      "                      Audio       0.30      0.82      0.44        66\n",
      "\n",
      "                  micro avg       0.68      0.71      0.69      4072\n",
      "                  macro avg       0.57      0.72      0.61      4072\n",
      "               weighted avg       0.74      0.71      0.71      4072\n",
      "                samples avg       0.70      0.71      0.69      4072\n",
      "\n",
      "Subset Accuracy: 0.3083, Hamming Loss: 0.2156, Precision (micro): 0.6766, Recall (micro): 0.7095, F1 (micro): 0.6926, F1 (macro): 0.6105\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.69      0.78      1582\n",
      "                     Graphs       0.45      0.61      0.52       502\n",
      "Natural Language Processing       0.83      0.72      0.77      1292\n",
      "     Reinforcement Learning       0.49      0.75      0.59       267\n",
      "                 Sequential       0.42      0.69      0.52       413\n",
      "                      Audio       0.27      0.79      0.40        66\n",
      "\n",
      "                  micro avg       0.67      0.70      0.68      4122\n",
      "                  macro avg       0.56      0.71      0.60      4122\n",
      "               weighted avg       0.74      0.70      0.70      4122\n",
      "                samples avg       0.70      0.70      0.68      4122\n",
      "\n",
      "Subset Accuracy: 0.2966, Hamming Loss: 0.2234, Precision (micro): 0.6701, Recall (micro): 0.6958, F1 (micro): 0.6827, F1 (macro): 0.5985\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.69      0.78      1566\n",
      "                     Graphs       0.48      0.61      0.54       502\n",
      "Natural Language Processing       0.82      0.73      0.77      1293\n",
      "     Reinforcement Learning       0.46      0.77      0.58       267\n",
      "                 Sequential       0.41      0.71      0.52       413\n",
      "                      Audio       0.34      0.86      0.48        66\n",
      "\n",
      "                  micro avg       0.67      0.70      0.68      4107\n",
      "                  macro avg       0.57      0.73      0.61      4107\n",
      "               weighted avg       0.74      0.70      0.70      4107\n",
      "                samples avg       0.69      0.70      0.68      4107\n",
      "\n",
      "Subset Accuracy: 0.2969, Hamming Loss: 0.2229, Precision (micro): 0.6679, Recall (micro): 0.7022, F1 (micro): 0.6846, F1 (macro): 0.6116\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - Abstract:\n",
      "Average Subset Accuracy: 0.2974\n",
      "Average Hamming Loss: 0.2235\n",
      "Average Precision (micro): 0.6667\n",
      "Average Recall (micro): 0.7002\n",
      "Average F1 (micro): 0.6830\n",
      "Average F1 (macro): 0.6002\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(abstracts)\n",
    "train_random_forest_multilabel(clip_embeddings, y, 'CLIP', 'Abstract')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.37      0.52      1657\n",
      "                     Graphs       0.32      0.86      0.46       501\n",
      "Natural Language Processing       0.85      0.42      0.56      1292\n",
      "     Reinforcement Learning       0.20      0.93      0.32       268\n",
      "                 Sequential       0.26      0.86      0.40       412\n",
      "                      Audio       0.36      0.36      0.36        66\n",
      "\n",
      "                  micro avg       0.41      0.53      0.46      4196\n",
      "                  macro avg       0.48      0.63      0.44      4196\n",
      "               weighted avg       0.70      0.53      0.50      4196\n",
      "                samples avg       0.47      0.53      0.48      4196\n",
      "\n",
      "Subset Accuracy: 0.1886, Hamming Loss: 0.4198, Precision (micro): 0.4117, Recall (micro): 0.5253, F1 (micro): 0.4616, F1 (macro): 0.4387\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.34      0.50      1499\n",
      "                     Graphs       0.33      0.87      0.48       501\n",
      "Natural Language Processing       0.88      0.36      0.51      1293\n",
      "     Reinforcement Learning       0.20      0.90      0.32       268\n",
      "                 Sequential       0.27      0.87      0.41       413\n",
      "                      Audio       0.04      0.88      0.09        65\n",
      "\n",
      "                  micro avg       0.33      0.51      0.40      4039\n",
      "                  macro avg       0.44      0.70      0.38      4039\n",
      "               weighted avg       0.70      0.51      0.47      4039\n",
      "                samples avg       0.42      0.51      0.44      4039\n",
      "\n",
      "Subset Accuracy: 0.1627, Hamming Loss: 0.5265, Precision (micro): 0.3300, Recall (micro): 0.5135, F1 (micro): 0.4018, F1 (macro): 0.3832\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.36      0.51      1530\n",
      "                     Graphs       0.32      0.88      0.47       502\n",
      "Natural Language Processing       0.86      0.38      0.53      1293\n",
      "     Reinforcement Learning       0.18      0.87      0.30       268\n",
      "                 Sequential       0.26      0.86      0.40       413\n",
      "                      Audio       0.25      0.39      0.31        66\n",
      "\n",
      "                  micro avg       0.40      0.51      0.45      4072\n",
      "                  macro avg       0.46      0.62      0.42      4072\n",
      "               weighted avg       0.69      0.51      0.48      4072\n",
      "                samples avg       0.45      0.51      0.47      4072\n",
      "\n",
      "Subset Accuracy: 0.1837, Hamming Loss: 0.4316, Precision (micro): 0.3990, Recall (micro): 0.5142, F1 (micro): 0.4494, F1 (macro): 0.4213\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.35      0.50      1582\n",
      "                     Graphs       0.61      0.33      0.43       502\n",
      "Natural Language Processing       0.85      0.39      0.54      1292\n",
      "     Reinforcement Learning       0.19      0.90      0.32       267\n",
      "                 Sequential       0.26      0.88      0.40       413\n",
      "                      Audio       0.05      0.91      0.09        66\n",
      "\n",
      "                  micro avg       0.35      0.46      0.40      4122\n",
      "                  macro avg       0.48      0.63      0.38      4122\n",
      "               weighted avg       0.73      0.46      0.48      4122\n",
      "                samples avg       0.41      0.46      0.42      4122\n",
      "\n",
      "Subset Accuracy: 0.1735, Hamming Loss: 0.4786, Precision (micro): 0.3518, Recall (micro): 0.4578, F1 (micro): 0.3978, F1 (macro): 0.3798\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.35      0.50      1566\n",
      "                     Graphs       0.32      0.86      0.47       502\n",
      "Natural Language Processing       0.86      0.38      0.52      1293\n",
      "     Reinforcement Learning       0.19      0.88      0.32       267\n",
      "                 Sequential       0.26      0.87      0.41       413\n",
      "                      Audio       0.07      0.27      0.11        66\n",
      "\n",
      "                  micro avg       0.39      0.50      0.44      4107\n",
      "                  macro avg       0.44      0.60      0.39      4107\n",
      "               weighted avg       0.70      0.50      0.48      4107\n",
      "                samples avg       0.43      0.51      0.46      4107\n",
      "\n",
      "Subset Accuracy: 0.1459, Hamming Loss: 0.4442, Precision (micro): 0.3886, Recall (micro): 0.5050, F1 (micro): 0.4392, F1 (macro): 0.3880\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - GitHub README Content:\n",
      "Average Subset Accuracy: 0.1709\n",
      "Average Hamming Loss: 0.4601\n",
      "Average Precision (micro): 0.3762\n",
      "Average Recall (micro): 0.5032\n",
      "Average F1 (micro): 0.4300\n",
      "Average F1 (macro): 0.4022\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(readmes)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y, 'TF-IDF', 'GitHub README Content')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y, 'TF-IDF', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.36      0.52      1657\n",
      "                     Graphs       0.30      0.81      0.43       501\n",
      "Natural Language Processing       0.80      0.39      0.53      1292\n",
      "     Reinforcement Learning       0.20      0.93      0.33       268\n",
      "                 Sequential       0.24      0.81      0.37       412\n",
      "                      Audio       0.25      0.35      0.29        66\n",
      "\n",
      "                  micro avg       0.39      0.51      0.44      4196\n",
      "                  macro avg       0.45      0.61      0.41      4196\n",
      "               weighted avg       0.68      0.51      0.48      4196\n",
      "                samples avg       0.44      0.51      0.46      4196\n",
      "\n",
      "Subset Accuracy: 0.1475, Hamming Loss: 0.4395, Precision (micro): 0.3908, Recall (micro): 0.5060, F1 (micro): 0.4410, F1 (macro): 0.4105\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.33      0.48      1499\n",
      "                     Graphs       0.30      0.82      0.44       501\n",
      "Natural Language Processing       0.81      0.33      0.47      1293\n",
      "     Reinforcement Learning       0.20      0.91      0.32       268\n",
      "                 Sequential       0.26      0.86      0.40       413\n",
      "                      Audio       0.05      0.80      0.09        65\n",
      "\n",
      "                  micro avg       0.32      0.49      0.39      4039\n",
      "                  macro avg       0.42      0.68      0.37      4039\n",
      "               weighted avg       0.67      0.49      0.45      4039\n",
      "                samples avg       0.40      0.49      0.43      4039\n",
      "\n",
      "Subset Accuracy: 0.1396, Hamming Loss: 0.5334, Precision (micro): 0.3211, Recall (micro): 0.4929, F1 (micro): 0.3889, F1 (macro): 0.3676\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.34      0.50      1530\n",
      "                     Graphs       0.31      0.84      0.45       502\n",
      "Natural Language Processing       0.82      0.36      0.50      1293\n",
      "     Reinforcement Learning       0.19      0.90      0.31       268\n",
      "                 Sequential       0.26      0.84      0.39       413\n",
      "                      Audio       0.40      0.38      0.39        66\n",
      "\n",
      "                  micro avg       0.39      0.50      0.44      4072\n",
      "                  macro avg       0.48      0.61      0.42      4072\n",
      "               weighted avg       0.68      0.50      0.47      4072\n",
      "                samples avg       0.44      0.50      0.46      4072\n",
      "\n",
      "Subset Accuracy: 0.1620, Hamming Loss: 0.4396, Precision (micro): 0.3888, Recall (micro): 0.4963, F1 (micro): 0.4360, F1 (macro): 0.4233\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.34      0.50      1582\n",
      "                     Graphs       0.50      0.29      0.36       502\n",
      "Natural Language Processing       0.79      0.37      0.50      1292\n",
      "     Reinforcement Learning       0.19      0.87      0.31       267\n",
      "                 Sequential       0.25      0.85      0.39       413\n",
      "                      Audio       0.05      0.91      0.10        66\n",
      "\n",
      "                  micro avg       0.34      0.44      0.38      4122\n",
      "                  macro avg       0.45      0.60      0.36      4122\n",
      "               weighted avg       0.70      0.44      0.45      4122\n",
      "                samples avg       0.40      0.44      0.40      4122\n",
      "\n",
      "Subset Accuracy: 0.1559, Hamming Loss: 0.4842, Precision (micro): 0.3425, Recall (micro): 0.4367, F1 (micro): 0.3839, F1 (macro): 0.3596\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.33      0.49      1566\n",
      "                     Graphs       0.30      0.82      0.43       502\n",
      "Natural Language Processing       0.81      0.35      0.49      1293\n",
      "     Reinforcement Learning       0.19      0.87      0.31       267\n",
      "                 Sequential       0.25      0.86      0.39       413\n",
      "                      Audio       0.21      0.27      0.24        66\n",
      "\n",
      "                  micro avg       0.38      0.49      0.43      4107\n",
      "                  macro avg       0.44      0.58      0.39      4107\n",
      "               weighted avg       0.68      0.49      0.46      4107\n",
      "                samples avg       0.43      0.49      0.44      4107\n",
      "\n",
      "Subset Accuracy: 0.1298, Hamming Loss: 0.4480, Precision (micro): 0.3820, Recall (micro): 0.4865, F1 (micro): 0.4280, F1 (macro): 0.3928\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - GitHub README Content:\n",
      "Average Subset Accuracy: 0.1470\n",
      "Average Hamming Loss: 0.4689\n",
      "Average Precision (micro): 0.3651\n",
      "Average Recall (micro): 0.4837\n",
      "Average F1 (micro): 0.4156\n",
      "Average F1 (macro): 0.3908\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(readmes)\n",
    "train_random_forest_multilabel(sentence_embeddings, y, 'Sentence Transformer', 'GitHub README Content')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y, 'Sentence Transformer', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (9954, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.88      0.34      0.49      1657\n",
      "                     Graphs       0.29      0.80      0.43       501\n",
      "Natural Language Processing       0.77      0.36      0.49      1292\n",
      "     Reinforcement Learning       0.18      0.90      0.31       268\n",
      "                 Sequential       0.23      0.80      0.36       412\n",
      "                      Audio       0.10      0.35      0.16        66\n",
      "\n",
      "                  micro avg       0.36      0.48      0.42      4196\n",
      "                  macro avg       0.41      0.59      0.37      4196\n",
      "               weighted avg       0.66      0.48      0.46      4196\n",
      "                samples avg       0.40      0.48      0.43      4196\n",
      "\n",
      "Subset Accuracy: 0.0921, Hamming Loss: 0.4667, Precision (micro): 0.3640, Recall (micro): 0.4845, F1 (micro): 0.4157, F1 (macro): 0.3730\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.89      0.31      0.46      1499\n",
      "                     Graphs       0.29      0.79      0.43       501\n",
      "Natural Language Processing       0.77      0.31      0.44      1293\n",
      "     Reinforcement Learning       0.18      0.88      0.30       268\n",
      "                 Sequential       0.24      0.80      0.37       413\n",
      "                      Audio       0.04      0.78      0.08        65\n",
      "\n",
      "                  micro avg       0.30      0.47      0.36      4039\n",
      "                  macro avg       0.40      0.65      0.35      4039\n",
      "               weighted avg       0.65      0.47      0.43      4039\n",
      "                samples avg       0.36      0.47      0.39      4039\n",
      "\n",
      "Subset Accuracy: 0.0936, Hamming Loss: 0.5629, Precision (micro): 0.2978, Recall (micro): 0.4674, F1 (micro): 0.3638, F1 (macro): 0.3467\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.88      0.32      0.47      1530\n",
      "                     Graphs       0.29      0.81      0.43       502\n",
      "Natural Language Processing       0.78      0.34      0.48      1293\n",
      "     Reinforcement Learning       0.17      0.82      0.28       268\n",
      "                 Sequential       0.24      0.80      0.37       413\n",
      "                      Audio       0.16      0.41      0.23        66\n",
      "\n",
      "                  micro avg       0.36      0.47      0.41      4072\n",
      "                  macro avg       0.42      0.58      0.38      4072\n",
      "               weighted avg       0.65      0.47      0.44      4072\n",
      "                samples avg       0.40      0.47      0.42      4072\n",
      "\n",
      "Subset Accuracy: 0.1024, Hamming Loss: 0.4712, Precision (micro): 0.3574, Recall (micro): 0.4715, F1 (micro): 0.4066, F1 (macro): 0.3760\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.32      0.47      1582\n",
      "                     Graphs       0.47      0.31      0.37       502\n",
      "Natural Language Processing       0.75      0.34      0.47      1292\n",
      "     Reinforcement Learning       0.18      0.82      0.29       267\n",
      "                 Sequential       0.23      0.79      0.36       413\n",
      "                      Audio       0.04      0.80      0.08        66\n",
      "\n",
      "                  micro avg       0.32      0.41      0.36      4122\n",
      "                  macro avg       0.43      0.56      0.34      4122\n",
      "               weighted avg       0.68      0.41      0.43      4122\n",
      "                samples avg       0.37      0.41      0.38      4122\n",
      "\n",
      "Subset Accuracy: 0.1141, Hamming Loss: 0.5054, Precision (micro): 0.3202, Recall (micro): 0.4127, F1 (micro): 0.3606, F1 (macro): 0.3416\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.31      0.47      1566\n",
      "                     Graphs       0.29      0.78      0.42       502\n",
      "Natural Language Processing       0.80      0.35      0.48      1293\n",
      "     Reinforcement Learning       0.17      0.82      0.29       267\n",
      "                 Sequential       0.24      0.83      0.38       413\n",
      "                      Audio       0.08      0.27      0.12        66\n",
      "\n",
      "                  micro avg       0.36      0.47      0.40      4107\n",
      "                  macro avg       0.41      0.56      0.36      4107\n",
      "               weighted avg       0.66      0.47      0.44      4107\n",
      "                samples avg       0.39      0.47      0.41      4107\n",
      "\n",
      "Subset Accuracy: 0.0830, Hamming Loss: 0.4743, Precision (micro): 0.3561, Recall (micro): 0.4663, F1 (micro): 0.4038, F1 (macro): 0.3591\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - GitHub README Content:\n",
      "Average Subset Accuracy: 0.0971\n",
      "Average Hamming Loss: 0.4961\n",
      "Average Precision (micro): 0.3391\n",
      "Average Recall (micro): 0.4605\n",
      "Average F1 (micro): 0.3901\n",
      "Average F1 (macro): 0.3593\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(readmes)\n",
    "train_random_forest_multilabel(clip_embeddings, y, 'CLIP', 'GitHub README Content')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y, 'CLIP', 'GitHub README Content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (4050, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.71      0.80       661\n",
      "                     Graphs       0.59      0.69      0.63       203\n",
      "Natural Language Processing       0.89      0.71      0.79       541\n",
      "     Reinforcement Learning       0.52      0.61      0.56        92\n",
      "                 Sequential       0.38      0.79      0.51       158\n",
      "                      Audio       0.20      0.75      0.32        28\n",
      "\n",
      "                  micro avg       0.69      0.71      0.70      1683\n",
      "                  macro avg       0.58      0.71      0.60      1683\n",
      "               weighted avg       0.78      0.71      0.73      1683\n",
      "                samples avg       0.72      0.71      0.70      1683\n",
      "\n",
      "Subset Accuracy: 0.3407, Hamming Loss: 0.2101, Precision (micro): 0.6911, Recall (micro): 0.7112, F1 (micro): 0.7010, F1 (macro): 0.6022\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.71      0.81       679\n",
      "                     Graphs       0.52      0.73      0.61       202\n",
      "Natural Language Processing       0.84      0.76      0.80       541\n",
      "     Reinforcement Learning       0.45      0.64      0.53        92\n",
      "                 Sequential       0.37      0.77      0.50       159\n",
      "                      Audio       0.09      0.89      0.16        28\n",
      "\n",
      "                  micro avg       0.61      0.73      0.67      1701\n",
      "                  macro avg       0.53      0.75      0.57      1701\n",
      "               weighted avg       0.76      0.73      0.73      1701\n",
      "                samples avg       0.66      0.74      0.67      1701\n",
      "\n",
      "Subset Accuracy: 0.2824, Hamming Loss: 0.2519, Precision (micro): 0.6113, Recall (micro): 0.7331, F1 (micro): 0.6667, F1 (macro): 0.5670\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.66      0.77       639\n",
      "                     Graphs       0.60      0.71      0.65       202\n",
      "Natural Language Processing       0.86      0.74      0.80       542\n",
      "     Reinforcement Learning       0.52      0.71      0.60        92\n",
      "                 Sequential       0.40      0.77      0.53       159\n",
      "                      Audio       0.16      0.79      0.27        28\n",
      "\n",
      "                  micro avg       0.68      0.71      0.69      1662\n",
      "                  macro avg       0.58      0.73      0.60      1662\n",
      "               weighted avg       0.78      0.71      0.72      1662\n",
      "                samples avg       0.71      0.71      0.69      1662\n",
      "\n",
      "Subset Accuracy: 0.3102, Hamming Loss: 0.2163, Precision (micro): 0.6774, Recall (micro): 0.7076, F1 (micro): 0.6922, F1 (macro): 0.6004\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.66      0.77       634\n",
      "                     Graphs       0.51      0.68      0.59       202\n",
      "Natural Language Processing       0.87      0.74      0.80       542\n",
      "     Reinforcement Learning       0.53      0.68      0.60        91\n",
      "                 Sequential       0.39      0.80      0.53       158\n",
      "                      Audio       0.08      0.69      0.14        29\n",
      "\n",
      "                  micro avg       0.62      0.70      0.66      1656\n",
      "                  macro avg       0.55      0.71      0.57      1656\n",
      "               weighted avg       0.77      0.70      0.71      1656\n",
      "                samples avg       0.66      0.71      0.67      1656\n",
      "\n",
      "Subset Accuracy: 0.3204, Hamming Loss: 0.2528, Precision (micro): 0.6175, Recall (micro): 0.7047, F1 (micro): 0.6582, F1 (macro): 0.5695\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.64      0.76       660\n",
      "                     Graphs       0.57      0.67      0.62       203\n",
      "Natural Language Processing       0.88      0.70      0.78       542\n",
      "     Reinforcement Learning       0.50      0.74      0.59        91\n",
      "                 Sequential       0.39      0.77      0.52       159\n",
      "                      Audio       0.14      0.62      0.23        29\n",
      "\n",
      "                  micro avg       0.67      0.68      0.68      1684\n",
      "                  macro avg       0.57      0.69      0.58      1684\n",
      "               weighted avg       0.78      0.68      0.71      1684\n",
      "                samples avg       0.70      0.69      0.67      1684\n",
      "\n",
      "Subset Accuracy: 0.3222, Hamming Loss: 0.2249, Precision (micro): 0.6729, Recall (micro): 0.6829, F1 (micro): 0.6779, F1 (macro): 0.5831\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "Average Subset Accuracy: 0.3152\n",
      "Average Hamming Loss: 0.2312\n",
      "Average Precision (micro): 0.6540\n",
      "Average Recall (micro): 0.7079\n",
      "Average F1 (micro): 0.6792\n",
      "Average F1 (macro): 0.5844\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(somef)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y_somef, 'TF-IDF', 'SOMEF descriptions')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y_somef, 'TF-IDF', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (4050, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.69      0.79       661\n",
      "                     Graphs       0.56      0.66      0.60       203\n",
      "Natural Language Processing       0.83      0.72      0.77       541\n",
      "     Reinforcement Learning       0.48      0.71      0.57        92\n",
      "                 Sequential       0.38      0.77      0.51       158\n",
      "                      Audio       0.23      0.89      0.37        28\n",
      "\n",
      "                  micro avg       0.68      0.71      0.69      1683\n",
      "                  macro avg       0.57      0.74      0.60      1683\n",
      "               weighted avg       0.76      0.71      0.72      1683\n",
      "                samples avg       0.70      0.72      0.69      1683\n",
      "\n",
      "Subset Accuracy: 0.3494, Hamming Loss: 0.2185, Precision (micro): 0.6751, Recall (micro): 0.7112, F1 (micro): 0.6927, F1 (macro): 0.6041\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.70      0.80       679\n",
      "                     Graphs       0.48      0.68      0.56       202\n",
      "Natural Language Processing       0.84      0.77      0.80       541\n",
      "     Reinforcement Learning       0.47      0.70      0.56        92\n",
      "                 Sequential       0.37      0.72      0.49       159\n",
      "                      Audio       0.28      0.93      0.43        28\n",
      "\n",
      "                  micro avg       0.67      0.72      0.70      1701\n",
      "                  macro avg       0.56      0.75      0.61      1701\n",
      "               weighted avg       0.76      0.72      0.72      1701\n",
      "                samples avg       0.71      0.73      0.70      1701\n",
      "\n",
      "Subset Accuracy: 0.3139, Hamming Loss: 0.2168, Precision (micro): 0.6716, Recall (micro): 0.7225, F1 (micro): 0.6961, F1 (macro): 0.6057\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.71      0.80       639\n",
      "                     Graphs       0.60      0.65      0.62       202\n",
      "Natural Language Processing       0.82      0.71      0.76       542\n",
      "     Reinforcement Learning       0.48      0.84      0.61        92\n",
      "                 Sequential       0.36      0.69      0.47       159\n",
      "                      Audio       0.23      0.86      0.36        28\n",
      "\n",
      "                  micro avg       0.67      0.71      0.69      1662\n",
      "                  macro avg       0.57      0.74      0.60      1662\n",
      "               weighted avg       0.76      0.71      0.72      1662\n",
      "                samples avg       0.71      0.71      0.69      1662\n",
      "\n",
      "Subset Accuracy: 0.3288, Hamming Loss: 0.2175, Precision (micro): 0.6737, Recall (micro): 0.7118, F1 (micro): 0.6922, F1 (macro): 0.6045\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.74      0.82       634\n",
      "                     Graphs       0.55      0.68      0.61       202\n",
      "Natural Language Processing       0.85      0.74      0.79       542\n",
      "     Reinforcement Learning       0.47      0.79      0.59        91\n",
      "                 Sequential       0.37      0.68      0.48       158\n",
      "                      Audio       0.25      0.72      0.38        29\n",
      "\n",
      "                  micro avg       0.69      0.73      0.71      1656\n",
      "                  macro avg       0.57      0.73      0.61      1656\n",
      "               weighted avg       0.76      0.73      0.73      1656\n",
      "                samples avg       0.72      0.73      0.71      1656\n",
      "\n",
      "Subset Accuracy: 0.3267, Hamming Loss: 0.2092, Precision (micro): 0.6858, Recall (micro): 0.7277, F1 (micro): 0.7061, F1 (macro): 0.6100\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.71      0.80       660\n",
      "                     Graphs       0.51      0.61      0.56       203\n",
      "Natural Language Processing       0.85      0.68      0.75       542\n",
      "     Reinforcement Learning       0.46      0.86      0.60        91\n",
      "                 Sequential       0.39      0.79      0.52       159\n",
      "                      Audio       0.25      0.59      0.35        29\n",
      "\n",
      "                  micro avg       0.68      0.70      0.69      1684\n",
      "                  macro avg       0.56      0.71      0.60      1684\n",
      "               weighted avg       0.76      0.70      0.71      1684\n",
      "                samples avg       0.70      0.70      0.68      1684\n",
      "\n",
      "Subset Accuracy: 0.3235, Hamming Loss: 0.2206, Precision (micro): 0.6753, Recall (micro): 0.7001, F1 (micro): 0.6875, F1 (macro): 0.5973\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "Average Subset Accuracy: 0.3284\n",
      "Average Hamming Loss: 0.2165\n",
      "Average Precision (micro): 0.6763\n",
      "Average Recall (micro): 0.7147\n",
      "Average F1 (micro): 0.6949\n",
      "Average F1 (macro): 0.6043\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(somef)\n",
    "train_random_forest_multilabel(sentence_embeddings, y_somef, 'Sentence Transformer', 'SOMEF descriptions')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y_somef, 'Sentence Transformer', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (4050, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.67      0.77       661\n",
      "                     Graphs       0.45      0.62      0.52       203\n",
      "Natural Language Processing       0.80      0.70      0.75       541\n",
      "     Reinforcement Learning       0.28      0.67      0.40        92\n",
      "                 Sequential       0.34      0.76      0.47       158\n",
      "                      Audio       0.17      0.89      0.29        28\n",
      "\n",
      "                  micro avg       0.59      0.68      0.63      1683\n",
      "                  macro avg       0.49      0.72      0.53      1683\n",
      "               weighted avg       0.72      0.68      0.68      1683\n",
      "                samples avg       0.63      0.69      0.64      1683\n",
      "\n",
      "Subset Accuracy: 0.2222, Hamming Loss: 0.2747, Precision (micro): 0.5890, Recall (micro): 0.6839, F1 (micro): 0.6329, F1 (macro): 0.5320\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.65      0.76       679\n",
      "                     Graphs       0.42      0.63      0.50       202\n",
      "Natural Language Processing       0.77      0.69      0.73       541\n",
      "     Reinforcement Learning       0.33      0.60      0.42        92\n",
      "                 Sequential       0.31      0.67      0.42       159\n",
      "                      Audio       0.15      0.86      0.26        28\n",
      "\n",
      "                  micro avg       0.58      0.66      0.62      1701\n",
      "                  macro avg       0.48      0.68      0.52      1701\n",
      "               weighted avg       0.71      0.66      0.66      1701\n",
      "                samples avg       0.62      0.66      0.62      1701\n",
      "\n",
      "Subset Accuracy: 0.2218, Hamming Loss: 0.2798, Precision (micro): 0.5818, Recall (micro): 0.6608, F1 (micro): 0.6188, F1 (macro): 0.5156\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.66      0.77       639\n",
      "                     Graphs       0.45      0.61      0.52       202\n",
      "Natural Language Processing       0.79      0.65      0.71       542\n",
      "     Reinforcement Learning       0.34      0.79      0.48        92\n",
      "                 Sequential       0.32      0.68      0.44       159\n",
      "                      Audio       0.15      0.86      0.26        28\n",
      "\n",
      "                  micro avg       0.59      0.67      0.62      1662\n",
      "                  macro avg       0.50      0.71      0.53      1662\n",
      "               weighted avg       0.72      0.67      0.67      1662\n",
      "                samples avg       0.63      0.67      0.62      1662\n",
      "\n",
      "Subset Accuracy: 0.2221, Hamming Loss: 0.2763, Precision (micro): 0.5864, Recall (micro): 0.6655, F1 (micro): 0.6234, F1 (macro): 0.5303\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.64      0.76       634\n",
      "                     Graphs       0.43      0.64      0.51       202\n",
      "Natural Language Processing       0.84      0.69      0.76       542\n",
      "     Reinforcement Learning       0.30      0.74      0.43        91\n",
      "                 Sequential       0.31      0.65      0.42       158\n",
      "                      Audio       0.12      0.59      0.20        29\n",
      "\n",
      "                  micro avg       0.58      0.66      0.62      1656\n",
      "                  macro avg       0.49      0.66      0.51      1656\n",
      "               weighted avg       0.73      0.66      0.67      1656\n",
      "                samples avg       0.62      0.67      0.62      1656\n",
      "\n",
      "Subset Accuracy: 0.2253, Hamming Loss: 0.2822, Precision (micro): 0.5804, Recall (micro): 0.6606, F1 (micro): 0.6179, F1 (macro): 0.5108\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.64      0.75       660\n",
      "                     Graphs       0.43      0.59      0.50       203\n",
      "Natural Language Processing       0.82      0.62      0.71       542\n",
      "     Reinforcement Learning       0.30      0.82      0.44        91\n",
      "                 Sequential       0.30      0.67      0.41       159\n",
      "                      Audio       0.13      0.55      0.21        29\n",
      "\n",
      "                  micro avg       0.57      0.64      0.60      1684\n",
      "                  macro avg       0.48      0.65      0.50      1684\n",
      "               weighted avg       0.72      0.64      0.65      1684\n",
      "                samples avg       0.60      0.64      0.60      1684\n",
      "\n",
      "Subset Accuracy: 0.2099, Hamming Loss: 0.2912, Precision (micro): 0.5716, Recall (micro): 0.6378, F1 (micro): 0.6029, F1 (macro): 0.5027\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - SOMEF descriptions:\n",
      "Average Subset Accuracy: 0.2203\n",
      "Average Hamming Loss: 0.2808\n",
      "Average Precision (micro): 0.5818\n",
      "Average Recall (micro): 0.6617\n",
      "Average F1 (micro): 0.6192\n",
      "Average F1 (macro): 0.5183\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(somef)\n",
    "train_random_forest_multilabel(clip_embeddings, y_somef, 'CLIP', 'SOMEF descriptions')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y_somef, 'CLIP', 'SOMEF descriptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.82      0.94      0.88       209\n",
      "                     Graphs       0.23      0.90      0.37        58\n",
      "Natural Language Processing       0.86      0.22      0.35       173\n",
      "     Reinforcement Learning       0.33      0.30      0.32        30\n",
      "                 Sequential       0.40      0.11      0.17        55\n",
      "                      Audio       0.05      1.00      0.09        11\n",
      "\n",
      "                  micro avg       0.40      0.58      0.47       536\n",
      "                  macro avg       0.45      0.58      0.36       536\n",
      "               weighted avg       0.68      0.58      0.53       536\n",
      "                samples avg       0.41      0.59      0.48       536\n",
      "\n",
      "Subset Accuracy: 0.0309, Hamming Loss: 0.4459, Precision (micro): 0.3997, Recall (micro): 0.5840, F1 (micro): 0.4746, F1 (macro): 0.3626\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.84      0.96      0.90       210\n",
      "                     Graphs       0.30      0.10      0.15        59\n",
      "Natural Language Processing       0.88      0.14      0.24       164\n",
      "     Reinforcement Learning       0.62      0.33      0.43        30\n",
      "                 Sequential       0.50      0.15      0.23        55\n",
      "                      Audio       0.40      0.18      0.25        11\n",
      "\n",
      "                  micro avg       0.78      0.47      0.59       529\n",
      "                  macro avg       0.59      0.31      0.37       529\n",
      "               weighted avg       0.74      0.47      0.50       529\n",
      "                samples avg       0.79      0.48      0.58       529\n",
      "\n",
      "Subset Accuracy: 0.0866, Hamming Loss: 0.2297, Precision (micro): 0.7771, Recall (micro): 0.4745, F1 (micro): 0.5892, F1 (macro): 0.3670\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.84      0.95      0.89       210\n",
      "                     Graphs       0.25      1.00      0.40        59\n",
      "Natural Language Processing       0.83      0.15      0.26       163\n",
      "     Reinforcement Learning       0.75      0.19      0.31        31\n",
      "                 Sequential       0.48      0.18      0.26        56\n",
      "                      Audio       0.25      0.18      0.21        11\n",
      "\n",
      "                  micro avg       0.56      0.57      0.56       530\n",
      "                  macro avg       0.57      0.44      0.39       530\n",
      "               weighted avg       0.72      0.57      0.53       530\n",
      "                samples avg       0.57      0.58      0.56       530\n",
      "\n",
      "Subset Accuracy: 0.1484, Hamming Loss: 0.3047, Precision (micro): 0.5572, Recall (micro): 0.5698, F1 (micro): 0.5634, F1 (macro): 0.3882\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.83      0.93      0.88       209\n",
      "                     Graphs       0.24      0.88      0.38        59\n",
      "Natural Language Processing       0.69      0.95      0.80       175\n",
      "     Reinforcement Learning       0.64      0.29      0.40        31\n",
      "                 Sequential       0.42      0.15      0.22        55\n",
      "                      Audio       0.04      1.00      0.08        11\n",
      "\n",
      "                  micro avg       0.45      0.82      0.58       540\n",
      "                  macro avg       0.48      0.70      0.46       540\n",
      "               weighted avg       0.65      0.82      0.69       540\n",
      "                samples avg       0.46      0.82      0.58       540\n",
      "\n",
      "Subset Accuracy: 0.0228, Hamming Loss: 0.4011, Precision (micro): 0.4523, Recall (micro): 0.8167, F1 (micro): 0.5822, F1 (macro): 0.4588\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.84      0.98      0.90       209\n",
      "                     Graphs       0.24      0.93      0.38        59\n",
      "Natural Language Processing       0.70      0.94      0.80       172\n",
      "     Reinforcement Learning       0.86      0.20      0.32        30\n",
      "                 Sequential       0.55      0.11      0.18        56\n",
      "                      Audio       0.80      0.36      0.50        11\n",
      "\n",
      "                  micro avg       0.60      0.82      0.69       537\n",
      "                  macro avg       0.66      0.59      0.51       537\n",
      "               weighted avg       0.70      0.82      0.70       537\n",
      "                samples avg       0.61      0.82      0.69       537\n",
      "\n",
      "Subset Accuracy: 0.0895, Hamming Loss: 0.2562, Precision (micro): 0.5967, Recall (micro): 0.8156, F1 (micro): 0.6892, F1 (macro): 0.5140\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - GitHub Title:\n",
      "Average Subset Accuracy: 0.0756\n",
      "Average Hamming Loss: 0.3275\n",
      "Average Precision (micro): 0.5566\n",
      "Average Recall (micro): 0.6521\n",
      "Average F1 (micro): 0.5797\n",
      "Average F1 (macro): 0.4181\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(github_title)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Title')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.86      0.51      0.64       209\n",
      "                     Graphs       0.30      0.62      0.40        58\n",
      "Natural Language Processing       0.78      0.65      0.71       173\n",
      "     Reinforcement Learning       0.23      0.57      0.33        30\n",
      "                 Sequential       0.28      0.55      0.37        55\n",
      "                      Audio       0.10      0.82      0.17        11\n",
      "\n",
      "                  micro avg       0.47      0.58      0.52       536\n",
      "                  macro avg       0.42      0.62      0.44       536\n",
      "               weighted avg       0.66      0.58      0.58       536\n",
      "                samples avg       0.50      0.58      0.51       536\n",
      "\n",
      "Subset Accuracy: 0.0772, Hamming Loss: 0.3707, Precision (micro): 0.4699, Recall (micro): 0.5821, F1 (micro): 0.5200, F1 (macro): 0.4378\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.89      0.56      0.69       210\n",
      "                     Graphs       0.36      0.69      0.48        59\n",
      "Natural Language Processing       0.73      0.63      0.68       164\n",
      "     Reinforcement Learning       0.28      0.67      0.39        30\n",
      "                 Sequential       0.30      0.53      0.38        55\n",
      "                      Audio       0.13      0.73      0.22        11\n",
      "\n",
      "                  micro avg       0.52      0.60      0.56       529\n",
      "                  macro avg       0.45      0.63      0.47       529\n",
      "               weighted avg       0.67      0.60      0.60       529\n",
      "                samples avg       0.54      0.61      0.55       529\n",
      "\n",
      "Subset Accuracy: 0.0906, Hamming Loss: 0.3333, Precision (micro): 0.5170, Recall (micro): 0.6030, F1 (micro): 0.5567, F1 (macro): 0.4724\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.87      0.64      0.74       210\n",
      "                     Graphs       0.33      0.56      0.42        59\n",
      "Natural Language Processing       0.74      0.62      0.67       163\n",
      "     Reinforcement Learning       0.23      0.61      0.33        31\n",
      "                 Sequential       0.31      0.61      0.41        56\n",
      "                      Audio       0.09      0.64      0.16        11\n",
      "\n",
      "                  micro avg       0.50      0.62      0.55       530\n",
      "                  macro avg       0.43      0.61      0.45       530\n",
      "               weighted avg       0.66      0.62      0.61       530\n",
      "                samples avg       0.52      0.62      0.54       530\n",
      "\n",
      "Subset Accuracy: 0.0977, Hamming Loss: 0.3483, Precision (micro): 0.4962, Recall (micro): 0.6189, F1 (micro): 0.5508, F1 (macro): 0.4544\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.84      0.56      0.67       209\n",
      "                     Graphs       0.30      0.61      0.40        59\n",
      "Natural Language Processing       0.75      0.65      0.70       175\n",
      "     Reinforcement Learning       0.22      0.61      0.32        31\n",
      "                 Sequential       0.29      0.56      0.39        55\n",
      "                      Audio       0.11      0.55      0.18        11\n",
      "\n",
      "                  micro avg       0.49      0.60      0.54       540\n",
      "                  macro avg       0.42      0.59      0.44       540\n",
      "               weighted avg       0.64      0.60      0.59       540\n",
      "                samples avg       0.51      0.60      0.53       540\n",
      "\n",
      "Subset Accuracy: 0.0760, Hamming Loss: 0.3523, Precision (micro): 0.4879, Recall (micro): 0.5981, F1 (micro): 0.5374, F1 (macro): 0.4423\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.86      0.61      0.72       209\n",
      "                     Graphs       0.30      0.51      0.38        59\n",
      "Natural Language Processing       0.77      0.59      0.67       172\n",
      "     Reinforcement Learning       0.19      0.67      0.30        30\n",
      "                 Sequential       0.32      0.59      0.41        56\n",
      "                      Audio       0.14      0.82      0.23        11\n",
      "\n",
      "                  micro avg       0.49      0.60      0.54       537\n",
      "                  macro avg       0.43      0.63      0.45       537\n",
      "               weighted avg       0.66      0.60      0.60       537\n",
      "                samples avg       0.51      0.60      0.53       537\n",
      "\n",
      "Subset Accuracy: 0.0817, Hamming Loss: 0.3547, Precision (micro): 0.4924, Recall (micro): 0.5996, F1 (micro): 0.5407, F1 (macro): 0.4518\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Title:\n",
      "Average Subset Accuracy: 0.0846\n",
      "Average Hamming Loss: 0.3519\n",
      "Average Precision (micro): 0.4927\n",
      "Average Recall (micro): 0.6004\n",
      "Average F1 (micro): 0.5411\n",
      "Average F1 (macro): 0.4517\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(github_title)\n",
    "train_random_forest_multilabel(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Title')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.83      0.57      0.67       209\n",
      "                     Graphs       0.31      0.62      0.41        58\n",
      "Natural Language Processing       0.79      0.61      0.69       173\n",
      "     Reinforcement Learning       0.19      0.60      0.29        30\n",
      "                 Sequential       0.27      0.56      0.36        55\n",
      "                      Audio       0.09      0.91      0.16        11\n",
      "\n",
      "                  micro avg       0.44      0.60      0.51       536\n",
      "                  macro avg       0.41      0.65      0.43       536\n",
      "               weighted avg       0.65      0.60      0.59       536\n",
      "                samples avg       0.46      0.59      0.50       536\n",
      "\n",
      "Subset Accuracy: 0.0618, Hamming Loss: 0.3964, Precision (micro): 0.4444, Recall (micro): 0.5970, F1 (micro): 0.5096, F1 (macro): 0.4311\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.87      0.55      0.67       210\n",
      "                     Graphs       0.33      0.58      0.42        59\n",
      "Natural Language Processing       0.72      0.59      0.65       164\n",
      "     Reinforcement Learning       0.19      0.60      0.29        30\n",
      "                 Sequential       0.27      0.53      0.35        55\n",
      "                      Audio       0.07      0.55      0.13        11\n",
      "\n",
      "                  micro avg       0.46      0.57      0.51       529\n",
      "                  macro avg       0.41      0.57      0.42       529\n",
      "               weighted avg       0.65      0.57      0.57       529\n",
      "                samples avg       0.46      0.57      0.49       529\n",
      "\n",
      "Subset Accuracy: 0.0709, Hamming Loss: 0.3839, Precision (micro): 0.4573, Recall (micro): 0.5671, F1 (micro): 0.5063, F1 (macro): 0.4199\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.86      0.57      0.68       210\n",
      "                     Graphs       0.33      0.68      0.44        59\n",
      "Natural Language Processing       0.73      0.63      0.67       163\n",
      "     Reinforcement Learning       0.21      0.58      0.31        31\n",
      "                 Sequential       0.33      0.50      0.40        56\n",
      "                      Audio       0.05      0.36      0.09        11\n",
      "\n",
      "                  micro avg       0.48      0.59      0.53       530\n",
      "                  macro avg       0.42      0.55      0.43       530\n",
      "               weighted avg       0.65      0.59      0.59       530\n",
      "                samples avg       0.48      0.59      0.52       530\n",
      "\n",
      "Subset Accuracy: 0.0977, Hamming Loss: 0.3659, Precision (micro): 0.4755, Recall (micro): 0.5868, F1 (micro): 0.5253, F1 (macro): 0.4311\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.85      0.49      0.62       209\n",
      "                     Graphs       0.26      0.49      0.34        59\n",
      "Natural Language Processing       0.78      0.62      0.69       175\n",
      "     Reinforcement Learning       0.17      0.61      0.26        31\n",
      "                 Sequential       0.32      0.69      0.44        55\n",
      "                      Audio       0.10      0.82      0.18        11\n",
      "\n",
      "                  micro avg       0.44      0.57      0.50       540\n",
      "                  macro avg       0.41      0.62      0.42       540\n",
      "               weighted avg       0.66      0.57      0.57       540\n",
      "                samples avg       0.47      0.57      0.49       540\n",
      "\n",
      "Subset Accuracy: 0.0570, Hamming Loss: 0.3935, Precision (micro): 0.4417, Recall (micro): 0.5685, F1 (micro): 0.4972, F1 (macro): 0.4224\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.82      0.58      0.68       209\n",
      "                     Graphs       0.29      0.59      0.39        59\n",
      "Natural Language Processing       0.73      0.55      0.63       172\n",
      "     Reinforcement Learning       0.19      0.53      0.28        30\n",
      "                 Sequential       0.27      0.50      0.35        56\n",
      "                      Audio       0.06      0.36      0.10        11\n",
      "\n",
      "                  micro avg       0.45      0.55      0.50       537\n",
      "                  macro avg       0.39      0.52      0.40       537\n",
      "               weighted avg       0.63      0.55      0.56       537\n",
      "                samples avg       0.45      0.56      0.48       537\n",
      "\n",
      "Subset Accuracy: 0.0739, Hamming Loss: 0.3865, Precision (micro): 0.4550, Recall (micro): 0.5549, F1 (micro): 0.5000, F1 (macro): 0.4035\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - GitHub Title:\n",
      "Average Subset Accuracy: 0.0723\n",
      "Average Hamming Loss: 0.3852\n",
      "Average Precision (micro): 0.4548\n",
      "Average Recall (micro): 0.5749\n",
      "Average F1 (micro): 0.5077\n",
      "Average F1 (macro): 0.4216\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(github_title)\n",
    "train_random_forest_multilabel(clip_embeddings, y_complete, 'CLIP', 'GitHub Title')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y_complete, 'CLIP', 'GitHub Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.94      0.56      0.70       209\n",
      "                     Graphs       0.47      0.76      0.58        58\n",
      "Natural Language Processing       0.88      0.75      0.81       173\n",
      "     Reinforcement Learning       0.62      0.70      0.66        30\n",
      "                 Sequential       0.41      0.75      0.53        55\n",
      "                      Audio       0.18      0.82      0.30        11\n",
      "\n",
      "                  micro avg       0.66      0.68      0.67       536\n",
      "                  macro avg       0.59      0.72      0.60       536\n",
      "               weighted avg       0.78      0.68      0.70       536\n",
      "                samples avg       0.68      0.68      0.66       536\n",
      "\n",
      "Subset Accuracy: 0.2857, Hamming Loss: 0.2310, Precision (micro): 0.6618, Recall (micro): 0.6754, F1 (micro): 0.6685, F1 (macro): 0.5974\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.66      0.76       210\n",
      "                     Graphs       0.66      0.53      0.58        59\n",
      "Natural Language Processing       0.79      0.81      0.80       164\n",
      "     Reinforcement Learning       0.69      0.73      0.71        30\n",
      "                 Sequential       0.36      0.67      0.47        55\n",
      "                      Audio       0.24      0.73      0.36        11\n",
      "\n",
      "                  micro avg       0.69      0.70      0.69       529\n",
      "                  macro avg       0.61      0.69      0.61       529\n",
      "               weighted avg       0.76      0.70      0.71       529\n",
      "                samples avg       0.70      0.70      0.68       529\n",
      "\n",
      "Subset Accuracy: 0.3189, Hamming Loss: 0.2152, Precision (micro): 0.6872, Recall (micro): 0.6975, F1 (micro): 0.6923, F1 (macro): 0.6143\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.87      0.75      0.81       210\n",
      "                     Graphs       0.45      0.69      0.55        59\n",
      "Natural Language Processing       0.85      0.77      0.81       163\n",
      "     Reinforcement Learning       0.61      0.87      0.72        31\n",
      "                 Sequential       0.39      0.82      0.53        56\n",
      "                      Audio       0.22      0.73      0.33        11\n",
      "\n",
      "                  micro avg       0.65      0.77      0.71       530\n",
      "                  macro avg       0.56      0.77      0.62       530\n",
      "               weighted avg       0.74      0.77      0.73       530\n",
      "                samples avg       0.71      0.77      0.72       530\n",
      "\n",
      "Subset Accuracy: 0.3047, Hamming Loss: 0.2201, Precision (micro): 0.6548, Recall (micro): 0.7660, F1 (micro): 0.7061, F1 (macro): 0.6243\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.68      0.78       209\n",
      "                     Graphs       0.49      0.63      0.55        59\n",
      "Natural Language Processing       0.85      0.76      0.80       175\n",
      "     Reinforcement Learning       0.57      0.81      0.67        31\n",
      "                 Sequential       0.47      0.67      0.56        55\n",
      "                      Audio       0.21      0.91      0.34        11\n",
      "\n",
      "                  micro avg       0.69      0.71      0.70       540\n",
      "                  macro avg       0.58      0.74      0.62       540\n",
      "               weighted avg       0.76      0.71      0.72       540\n",
      "                samples avg       0.71      0.72      0.69       540\n",
      "\n",
      "Subset Accuracy: 0.3346, Hamming Loss: 0.2098, Precision (micro): 0.6863, Recall (micro): 0.7130, F1 (micro): 0.6994, F1 (macro): 0.6154\n",
      "-----------------------------------\n",
      "Fold Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.89      0.72      0.80       209\n",
      "                     Graphs       0.49      0.59      0.53        59\n",
      "Natural Language Processing       0.85      0.80      0.82       172\n",
      "     Reinforcement Learning       0.71      0.73      0.72        30\n",
      "                 Sequential       0.46      0.68      0.55        56\n",
      "                      Audio       0.47      0.73      0.57        11\n",
      "\n",
      "                  micro avg       0.73      0.73      0.73       537\n",
      "                  macro avg       0.64      0.71      0.67       537\n",
      "               weighted avg       0.77      0.73      0.74       537\n",
      "                samples avg       0.77      0.74      0.73       537\n",
      "\n",
      "Subset Accuracy: 0.3735, Hamming Loss: 0.1874, Precision (micro): 0.7313, Recall (micro): 0.7300, F1 (micro): 0.7307, F1 (macro): 0.6658\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for TF-IDF (OvR RF, Multi-label) - GitHub Keywords:\n",
      "Average Subset Accuracy: 0.3235\n",
      "Average Hamming Loss: 0.2127\n",
      "Average Precision (micro): 0.6843\n",
      "Average Recall (micro): 0.7164\n",
      "Average F1 (micro): 0.6994\n",
      "Average F1 (macro): 0.6234\n"
     ]
    }
   ],
   "source": [
    "tfidf_embeddings = compute_tfidf(github_keywords)\n",
    "train_random_forest_multilabel(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Keywords')\n",
    "# evaluate_clustering_metrics(tfidf_embeddings, y_complete, 'TF-IDF', 'GitHub Keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.68      0.78       209\n",
      "                     Graphs       0.51      0.76      0.61        58\n",
      "Natural Language Processing       0.82      0.68      0.74       173\n",
      "     Reinforcement Learning       0.64      0.70      0.67        30\n",
      "                 Sequential       0.40      0.76      0.53        55\n",
      "                      Audio       0.21      0.82      0.33        11\n",
      "\n",
      "                  micro avg       0.67      0.70      0.68       536\n",
      "                  macro avg       0.58      0.73      0.61       536\n",
      "               weighted avg       0.76      0.70      0.71       536\n",
      "                samples avg       0.70      0.70      0.69       536\n",
      "\n",
      "Subset Accuracy: 0.3243, Hamming Loss: 0.2239, Precision (micro): 0.6673, Recall (micro): 0.6996, F1 (micro): 0.6831, F1 (macro): 0.6106\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.75      0.82       210\n",
      "                     Graphs       0.53      0.54      0.54        59\n",
      "Natural Language Processing       0.76      0.73      0.75       164\n",
      "     Reinforcement Learning       0.56      0.73      0.64        30\n",
      "                 Sequential       0.39      0.65      0.49        55\n",
      "                      Audio       0.24      0.73      0.36        11\n",
      "\n",
      "                  micro avg       0.67      0.71      0.69       529\n",
      "                  macro avg       0.57      0.69      0.60       529\n",
      "               weighted avg       0.73      0.71      0.71       529\n",
      "                samples avg       0.71      0.71      0.69       529\n",
      "\n",
      "Subset Accuracy: 0.2992, Hamming Loss: 0.2198, Precision (micro): 0.6745, Recall (micro): 0.7089, F1 (micro): 0.6912, F1 (macro): 0.5985\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.70      0.79       210\n",
      "                     Graphs       0.44      0.61      0.51        59\n",
      "Natural Language Processing       0.84      0.78      0.81       163\n",
      "     Reinforcement Learning       0.52      0.87      0.65        31\n",
      "                 Sequential       0.43      0.68      0.53        56\n",
      "                      Audio       0.33      0.82      0.47        11\n",
      "\n",
      "                  micro avg       0.68      0.72      0.70       530\n",
      "                  macro avg       0.58      0.74      0.63       530\n",
      "               weighted avg       0.75      0.72      0.72       530\n",
      "                samples avg       0.72      0.73      0.71       530\n",
      "\n",
      "Subset Accuracy: 0.3555, Hamming Loss: 0.2122, Precision (micro): 0.6809, Recall (micro): 0.7245, F1 (micro): 0.7020, F1 (macro): 0.6263\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.92      0.73      0.81       209\n",
      "                     Graphs       0.46      0.68      0.55        59\n",
      "Natural Language Processing       0.81      0.78      0.79       175\n",
      "     Reinforcement Learning       0.56      0.81      0.66        31\n",
      "                 Sequential       0.46      0.69      0.55        55\n",
      "                      Audio       0.34      0.91      0.50        11\n",
      "\n",
      "                  micro avg       0.69      0.74      0.72       540\n",
      "                  macro avg       0.59      0.77      0.64       540\n",
      "               weighted avg       0.75      0.74      0.74       540\n",
      "                samples avg       0.71      0.75      0.71       540\n",
      "\n",
      "Subset Accuracy: 0.3688, Hamming Loss: 0.2003, Precision (micro): 0.6931, Recall (micro): 0.7444, F1 (micro): 0.7179, F1 (macro): 0.6436\n",
      "-----------------------------------\n",
      "Fold Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.77      0.84       209\n",
      "                     Graphs       0.49      0.64      0.55        59\n",
      "Natural Language Processing       0.84      0.83      0.83       172\n",
      "     Reinforcement Learning       0.71      0.67      0.69        30\n",
      "                 Sequential       0.39      0.64      0.49        56\n",
      "                      Audio       0.32      0.64      0.42        11\n",
      "\n",
      "                  micro avg       0.72      0.75      0.73       537\n",
      "                  macro avg       0.61      0.70      0.64       537\n",
      "               weighted avg       0.77      0.75      0.75       537\n",
      "                samples avg       0.75      0.76      0.73       537\n",
      "\n",
      "Subset Accuracy: 0.3619, Hamming Loss: 0.1907, Precision (micro): 0.7150, Recall (micro): 0.7523, F1 (micro): 0.7332, F1 (macro): 0.6374\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for Sentence Transformer (OvR RF, Multi-label) - GitHub Keywords:\n",
      "Average Subset Accuracy: 0.3419\n",
      "Average Hamming Loss: 0.2094\n",
      "Average Precision (micro): 0.6861\n",
      "Average Recall (micro): 0.7260\n",
      "Average F1 (micro): 0.7055\n",
      "Average F1 (macro): 0.6233\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = compute_sentence_embeddings(github_keywords)\n",
    "train_random_forest_multilabel(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Keywords')\n",
    "# evaluate_clustering_metrics(sentence_embeddings, y_complete, 'Sentence Transformer', 'GitHub Keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted labels with MultiLabelBinarizer. Shape: (1289, 6)\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.93      0.67      0.78       209\n",
      "                     Graphs       0.45      0.72      0.55        58\n",
      "Natural Language Processing       0.83      0.68      0.75       173\n",
      "     Reinforcement Learning       0.62      0.70      0.66        30\n",
      "                 Sequential       0.35      0.69      0.46        55\n",
      "                      Audio       0.21      0.73      0.32        11\n",
      "\n",
      "                  micro avg       0.64      0.68      0.66       536\n",
      "                  macro avg       0.56      0.70      0.59       536\n",
      "               weighted avg       0.75      0.68      0.69       536\n",
      "                samples avg       0.68      0.69      0.66       536\n",
      "\n",
      "Subset Accuracy: 0.2471, Hamming Loss: 0.2400, Precision (micro): 0.6432, Recall (micro): 0.6828, F1 (micro): 0.6624, F1 (macro): 0.5855\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.72      0.80       210\n",
      "                     Graphs       0.47      0.53      0.50        59\n",
      "Natural Language Processing       0.78      0.79      0.78       164\n",
      "     Reinforcement Learning       0.75      0.70      0.72        30\n",
      "                 Sequential       0.36      0.56      0.44        55\n",
      "                      Audio       0.22      0.73      0.34        11\n",
      "\n",
      "                  micro avg       0.68      0.70      0.69       529\n",
      "                  macro avg       0.58      0.67      0.60       529\n",
      "               weighted avg       0.74      0.70      0.71       529\n",
      "                samples avg       0.70      0.70      0.68       529\n",
      "\n",
      "Subset Accuracy: 0.2992, Hamming Loss: 0.2198, Precision (micro): 0.6770, Recall (micro): 0.7013, F1 (micro): 0.6890, F1 (macro): 0.5978\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.89      0.67      0.76       210\n",
      "                     Graphs       0.43      0.68      0.53        59\n",
      "Natural Language Processing       0.86      0.74      0.80       163\n",
      "     Reinforcement Learning       0.57      0.84      0.68        31\n",
      "                 Sequential       0.41      0.64      0.50        56\n",
      "                      Audio       0.24      0.82      0.37        11\n",
      "\n",
      "                  micro avg       0.66      0.70      0.68       530\n",
      "                  macro avg       0.56      0.73      0.60       530\n",
      "               weighted avg       0.74      0.70      0.71       530\n",
      "                samples avg       0.70      0.71      0.68       530\n",
      "\n",
      "Subset Accuracy: 0.2930, Hamming Loss: 0.2272, Precision (micro): 0.6602, Recall (micro): 0.7038, F1 (micro): 0.6813, F1 (macro): 0.6049\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.90      0.71      0.79       209\n",
      "                     Graphs       0.48      0.66      0.55        59\n",
      "Natural Language Processing       0.86      0.78      0.81       175\n",
      "     Reinforcement Learning       0.60      0.81      0.68        31\n",
      "                 Sequential       0.46      0.78      0.58        55\n",
      "                      Audio       0.33      0.82      0.47        11\n",
      "\n",
      "                  micro avg       0.70      0.74      0.72       540\n",
      "                  macro avg       0.60      0.76      0.65       540\n",
      "               weighted avg       0.76      0.74      0.74       540\n",
      "                samples avg       0.74      0.75      0.72       540\n",
      "\n",
      "Subset Accuracy: 0.3194, Hamming Loss: 0.1952, Precision (micro): 0.7042, Recall (micro): 0.7407, F1 (micro): 0.7220, F1 (macro): 0.6498\n",
      "-----------------------------------\n",
      "Fold Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            Computer Vision       0.91      0.71      0.80       209\n",
      "                     Graphs       0.46      0.61      0.52        59\n",
      "Natural Language Processing       0.83      0.83      0.83       172\n",
      "     Reinforcement Learning       0.53      0.70      0.60        30\n",
      "                 Sequential       0.42      0.62      0.50        56\n",
      "                      Audio       0.24      0.64      0.35        11\n",
      "\n",
      "                  micro avg       0.69      0.73      0.71       537\n",
      "                  macro avg       0.56      0.69      0.60       537\n",
      "               weighted avg       0.75      0.73      0.73       537\n",
      "                samples avg       0.72      0.73      0.70       537\n",
      "\n",
      "Subset Accuracy: 0.2957, Hamming Loss: 0.2108, Precision (micro): 0.6866, Recall (micro): 0.7263, F1 (micro): 0.7059, F1 (macro): 0.5994\n",
      "-----------------------------------\n",
      "Final Cross-Validated Results for CLIP (OvR RF, Multi-label) - GitHub Keywords:\n",
      "Average Subset Accuracy: 0.2909\n",
      "Average Hamming Loss: 0.2186\n",
      "Average Precision (micro): 0.6743\n",
      "Average Recall (micro): 0.7110\n",
      "Average F1 (micro): 0.6921\n",
      "Average F1 (macro): 0.6075\n"
     ]
    }
   ],
   "source": [
    "clip_embeddings = compute_clip_embeddings(github_keywords)\n",
    "train_random_forest_multilabel(clip_embeddings, y_complete, 'CLIP', 'GitHub Keywords')\n",
    "# evaluate_clustering_metrics(clip_embeddings, y_complete, 'CLIP', 'GitHub Keywords')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
